{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2ab15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from kagglehub) (23.0)\n",
      "Requirement already satisfied: requests in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from kagglehub) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from requests->kagglehub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6698e95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API key is correctly placed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the environment variable for Kaggle is set\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = os.path.expanduser(\"~/.kaggle\")\n",
    "\n",
    "# Confirm the Kaggle file is accessible\n",
    "kaggle_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "if os.path.exists(kaggle_path):\n",
    "    print(\"Kaggle API key is correctly placed.\")\n",
    "else:\n",
    "    print(\"Kaggle API key is missing. Please check the file path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c31a46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tushar jain\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2dd3727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.11)\n",
      "Path to dataset files: C:\\Users\\Tushar Jain\\.cache\\kagglehub\\datasets\\ananysrivastava\\birde-drone\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"ananysrivastava/birde-drone\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "facb5e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar Jain\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tushar Jain\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [27:22<00:00, 13.46s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:19<00:00,  4.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3664, Train Accuracy: 79.64%\n",
      "Val Loss: 1.0077, Val Accuracy: 70.49%\n",
      "Best model saved.\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [25:53<00:00, 12.73s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:49<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2700, Train Accuracy: 84.55%\n",
      "Val Loss: 0.4000, Val Accuracy: 84.11%\n",
      "Best model saved.\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [28:00<00:00, 13.77s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:38<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1981, Train Accuracy: 89.22%\n",
      "Val Loss: 0.1587, Val Accuracy: 90.20%\n",
      "Best model saved.\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [24:52<00:00, 12.23s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:26<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3807, Train Accuracy: 79.39%\n",
      "Val Loss: 0.5420, Val Accuracy: 78.22%\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [26:17<00:00, 12.93s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:27<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2670, Train Accuracy: 82.66%\n",
      "Val Loss: 0.2682, Val Accuracy: 81.84%\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [23:28<00:00, 11.55s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:19<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2582, Train Accuracy: 82.46%\n",
      "Val Loss: 0.2373, Val Accuracy: 83.38%\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [29:06<00:00, 14.32s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:17<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2447, Train Accuracy: 83.33%\n",
      "Val Loss: 0.2374, Val Accuracy: 83.38%\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [25:11<00:00, 12.39s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:09<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2369, Train Accuracy: 83.57%\n",
      "Val Loss: 0.6261, Val Accuracy: 82.46%\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [21:43<00:00, 10.68s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:18<00:00,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2216, Train Accuracy: 86.79%\n",
      "Val Loss: 0.2785, Val Accuracy: 86.69%\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [28:13<00:00, 13.88s/it]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [02:17<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2142, Train Accuracy: 88.47%\n",
      "Val Loss: 0.1919, Val Accuracy: 90.71%\n",
      "Best model saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):  # Corrected __init__\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  # Corrected __len__\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):  # Corrected __getitem__\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Transformations for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set paths and labels\n",
    "base_dir = r\"C:\\Users\\Tushar Jain\\.cache\\kagglehub\\datasets\\ananysrivastava\\birde-drone\\versions\\1\"\n",
    "image_dirs = {\n",
    "    'bird': [os.path.join(base_dir, 'bird_results', 'spectrograms'),\n",
    "             os.path.join(base_dir, 'bird_results', 'cepstrograms'),\n",
    "             os.path.join(base_dir, 'bird_results', 'cvds')],\n",
    "    'drone+bird': [os.path.join(base_dir, 'bird+drone_results', 'spectrograms'),\n",
    "                   os.path.join(base_dir, 'bird+drone_results', 'cepstrograms'),\n",
    "                   os.path.join(base_dir, 'bird+drone_results', 'cvds')],\n",
    "    'drone': [os.path.join(base_dir, 'drone2 results', 'spectrograms'),\n",
    "              os.path.join(base_dir, 'drone2 results', 'cepstrograms'),\n",
    "              os.path.join(base_dir, 'drone2 results', 'cvds')]\n",
    "}\n",
    "\n",
    "image_paths, labels = [], []\n",
    "for label, (category, dirs) in enumerate(image_dirs.items()):\n",
    "    for dir in dirs:\n",
    "        if os.path.exists(dir):\n",
    "            for filename in os.listdir(dir):\n",
    "                if filename.endswith(('.png', '.jpg')):\n",
    "                    image_paths.append(os.path.join(dir, filename))\n",
    "                    labels.append(label)\n",
    "\n",
    "# Split data\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.2, stratify=labels)\n",
    "\n",
    "# Loaders\n",
    "train_dataset = CustomDataset(train_paths, train_labels, transform=transform)\n",
    "val_dataset = CustomDataset(val_paths, val_labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ResNet-50 for feature extraction and training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "num_classes = len(image_dirs)\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_resnet(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_accuracy = correct / total * 100\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "# Validation function\n",
    "def validate_resnet(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_accuracy = correct / total * 100\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "# Train ResNet-50\n",
    "num_epochs = 10\n",
    "best_val_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss, train_accuracy = train_resnet(resnet, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_accuracy = validate_resnet(resnet, val_loader, criterion, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(resnet.state_dict(), \"resnet50_best_model.pth\")\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "# Feature extraction\n",
    "resnet.fc = nn.Identity()  # Remove classification head for feature extraction\n",
    "resnet.eval()\n",
    "def extract_features(model, dataloader):\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "            labels.extend(targets.numpy())\n",
    "    return np.vstack(features), np.array(labels)\n",
    "\n",
    "train_features, train_labels = extract_features(resnet, train_loader)\n",
    "val_features, val_labels = extract_features(resnet, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892c1999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA for dimensionality reduction\n",
    "pca = PCA(n_components=50)\n",
    "train_features_pca = pca.fit_transform(train_features)\n",
    "val_features_pca = pca.transform(val_features)\n",
    "joblib.dump(pca, 'pca_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f50500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 93.09%\n",
      "KNN Accuracy: 95.67%\n",
      "Random Forest Accuracy: 96.49%\n",
      "Logistic Regression Accuracy: 94.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train models\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the models on PCA-transformed training features\n",
    "svm.fit(train_features_pca, train_labels)\n",
    "knn.fit(train_features_pca, train_labels)\n",
    "rf.fit(train_features_pca, train_labels)\n",
    "lr.fit(train_features_pca, train_labels)\n",
    "\n",
    "# Evaluate the models on the PCA-transformed validation features\n",
    "svm_preds = svm.predict(val_features_pca)\n",
    "knn_preds = knn.predict(val_features_pca)\n",
    "rf_preds = rf.predict(val_features_pca)\n",
    "lr_preds = lr.predict(val_features_pca)\n",
    "\n",
    "# Calculate accuracies\n",
    "svm_accuracy = accuracy_score(val_labels, svm_preds)\n",
    "knn_accuracy = accuracy_score(val_labels, knn_preds)\n",
    "rf_accuracy = accuracy_score(val_labels, rf_preds)\n",
    "lr_accuracy = accuracy_score(val_labels, lr_preds)\n",
    "\n",
    "# Print the accuracies\n",
    "print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n",
    "print(f\"KNN Accuracy: {knn_accuracy * 100:.2f}%\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy * 100:.2f}%\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3771d7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(svm, 'svm_model.pkl')\n",
    "joblib.dump(knn, 'knn_model.pkl')\n",
    "joblib.dump(rf, 'rf_model.pkl')\n",
    "joblib.dump(lr, 'lr_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe73f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy (Majority Voting): 95.56%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get predictions from each model\n",
    "svm_preds = svm.predict(val_features_pca)\n",
    "knn_preds = knn.predict(val_features_pca)\n",
    "rf_preds = rf.predict(val_features_pca)\n",
    "lr_preds = lr.predict(val_features_pca)\n",
    "\n",
    "# Stack predictions\n",
    "all_preds = np.array([svm_preds, knn_preds, rf_preds, lr_preds])\n",
    "\n",
    "# Perform majority voting\n",
    "ensemble_preds = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_preds)\n",
    "\n",
    "# Evaluate ensemble accuracy\n",
    "ensemble_accuracy = accuracy_score(val_labels, ensemble_preds)\n",
    "print(f\"Ensemble Accuracy (Majority Voting): {ensemble_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f632126a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy (Weighted Voting): 95.98%\n"
     ]
    }
   ],
   "source": [
    "# Define weights based on validation accuracy\n",
    "weights = [svm_accuracy, knn_accuracy, rf_accuracy, lr_accuracy]\n",
    "\n",
    "# Get probabilities for weighted voting\n",
    "svm_probs = svm.predict_proba(val_features_pca)\n",
    "knn_probs = knn.predict_proba(val_features_pca)\n",
    "rf_probs = rf.predict_proba(val_features_pca)\n",
    "lr_probs = lr.predict_proba(val_features_pca)\n",
    "\n",
    "# Weighted sum of probabilities\n",
    "ensemble_probs = (\n",
    "    weights[0] * svm_probs +\n",
    "    weights[1] * knn_probs +\n",
    "    weights[2] * rf_probs +\n",
    "    weights[3] * lr_probs\n",
    ")\n",
    "\n",
    "# Final predictions from the highest probability class\n",
    "ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "\n",
    "# Evaluate ensemble accuracy\n",
    "ensemble_accuracy = accuracy_score(val_labels, ensemble_preds)\n",
    "print(f\"Ensemble Accuracy (Weighted Voting): {ensemble_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "664f5d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy: 96.18%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define the base models\n",
    "base_estimators = [\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('rf', rf),\n",
    "    ('lr', lr)\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train the stacking model\n",
    "stack_model.fit(train_features_pca, train_labels)\n",
    "\n",
    "# Evaluate stacking model accuracy\n",
    "stack_accuracy = stack_model.score(val_features_pca, val_labels)\n",
    "print(f\"Stacking Accuracy: {stack_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b218c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
